<!doctype html>
<!--[if lt IE 7 ]> <html class="no-js ie6" lang="en"> <![endif]-->
<!--[if IE 7 ]>	   <html class="no-js ie7" lang="en"> <![endif]-->
<!--[if IE 8 ]>	   <html class="no-js ie8" lang="en"> <![endif]-->
<!--[if (gte IE 9)|!(IE)]><!--> <html class="no-js" lang="en"> <!--<![endif]-->
<head><meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
<meta name="version" content="4.0">
<meta name="author" content="Puneet Kishor">
<meta name="copyright" content="CC0 Public Domain Dedication">
<meta http-equiv="Cache-Control" content="max-age=604800, public">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

<title>punkish: Digital Manaslu</title>

<!-- see https://stackoverflow.com/questions/1321878/how-to-prevent-favicon-ico-requests -->
<link rel="icon" href="data:;base64,iVBORw0KGgo=">

<link rel="stylesheet" href="punkish/_lib/css/fonts.css">
<link rel="stylesheet" href="punkish/_lib/css/styles.css">
<link rel="stylesheet" href="punkish/_lib/JavaScript-autoComplete/auto-complete.css">






</head>
<body>
    <header class="row"><div>
    <a href="/" class="home">

        <img src="punkish/_lib/img/PunkishEidesisOrg.gif">
    </a> 

    <form name="search" method="GET" action="/entries">
        <input name="q" type="text" placeholder="there are none so blind as those who don’t see">
    </form>
</div>
<nav>
    <a href="punkish/cv-latest/">cv</a>
    <a href="punkish/Where/">where</a>
    <a href="punkish/_dates/">dates</a>
    <a href="punkish/_tags/">tags</a>
</nav></header>
    
    <main><section>
    <h1 class="title">Digital Manaslu</h1>
    <div class="description"></div>
    <div class="created">Tuesday, January 1, 1980</div>
    
    <div class="content"><p>SUB has received a unique collection of analog photos (prints and slides) from various expeditions to Nepal undertaken over a period of time—a legacy of Professor Matthias Kuhle. Curation is being carried out jointly with the Department of Geosciences at the University of Göttingen. These are invaluable photos because they offer a time-series view (repeated expeditions to the same locations over many years) at a very high resolution. However, while we have the time when the photos was taken, there is no geolocation available for these photos, that is, where the photographer was standing and which way he was looking when he took these photos. This short paper examines the various approaches to geolocate the photos, pin them on a map of the region, and make them available for dissemination.</p>
<h2 id="step1digitizethephotos">Step 1: Digitize the Photos</h2>
<p>The first step is to digitize the photos. Digitization is a one-time investment, so we want the best digitization possible (but no more than necessary), and then down-sample for application-specific use. Digitization is an essential step and the subsequent steps depend on it. This can be spun off as a separate project for the dual objectives of archival and research, hence, funding for this step could be sought from different agencies. The subsequent steps of identifying/locating and displaying/disseminating are dependent on digitization of the photographs, however, these steps don’t have to wait for digitization of all photographs to finish. Even a small corpus of photographs that have already been digitized should be enough to start steps 2a and 2b. These steps themselves are not dependent on each other as they can be developed concurrently. Together, they do, however, set up a feedback loop whereby the identification and location of the displayed photos can be continuously improved until determined to be good enough.</p>
<h2 id="step2identifyandlocate">Step 2: Identify and Locate</h2>
<p>Multiple strategies may be followed for identification and location. And since display and dissemination are a part of the process of identification and location, the two activities can be conducted concurrently in a dependent system of continuous feedback and improvement. The current method of one person using the process of visually identifying geographic features on a web-based map (such as Google Maps) and using that to mark the photos is extremely painstaking and time-consuming. We need to enlist a combination of crowdsourcing, location match and machine-learning to create a bigger dataset quickly, and then apply the secondary step of expert checking and confirmation.</p>
<h3 id="2acrowdsource">2a. Crowdsource</h3>
<p>The idea behind this is to enlist a crowd to do what one person is doing right now. The mechanism is quite like the current way of identification/location—present a photo and a web-based satellite view side-by-side, and have a user mark the correct location. Even if a certain percentage of the identification/location results may be wrong, given a big enough crowd, the decision will converge toward a truth that can be verified by an expert. There are few web-based platforms, listed below, that may allow us to construct such a project.</p>
<h4 id="2a1crowdcrafting">2a.1. Crowdcrafting</h4>
<p>Crowdcrafting is a web-based service that invites volunteers to contribute to scientific projects developed by citizens, professionals or institutions that need help to solve problems, analyze data or complete challenging tasks that can’t be done by machines alone, but require human intelligence. The platform is 100% open source - that is its software is developed and distributed freely - and 100% open-science, making scientific research accessible to everyone.</p>
<h4 id="2a2zooniverse">2a.2. Zooniverse</h4>
<p>The Zooniverse is the world’s largest and most popular platform for people-powered research. This research is made possible by volunteers—hundreds of thousands of people around the world who come together to assist professional researchers. Our goal is to enable research that would not be possible, or practical, otherwise.</p>
<h4 id="2a3scribeproject">2a.3. Scribe Project</h4>
<p>Scribe, built upon Zooniverse, is a highly configurable, open source framework for setting up community transcription projects around handwritten or OCR-resistant texts. Scribe is particularly geared toward digital humanities, library, and citizen science projects seeking to extract highly structured, normalizable data from a set of digitized materials (e.g. historical manuscripts, account ledgers, catalog cards, or maritime logbooks).</p>
<h3 id="2blocationmatch">2b. Location Match</h3>
<h4 id="2b1heywhatsthat">2b.1. Hey What’s That</h4>
<p>You hike to the top of a mountain or pull off at a scenic overlook. You see mountains in the distance. Which mountains are they? HeyWhatsThat will tell you, providing a 360° panoramic sketch labeled with the names of the peaks you're looking at. From almost anywhere in the world. Also available for smartphones.</p>
<h4 id="2b2peakar">2b.2. Peak.AR</h4>
<p>Peak.ar demonstrates the augmented reality technology that was developed in the course of a research project. It is a very flexible tool that can be used to visualize any kind of geo-referenced data. At the same time it is the most intuitive way for interfacing with complex data from a user’s perspective – just point your phone to some real world object and it will tell you everything it knows about it. </p>
<h4 id="2b3peakfinder">2b.3. PeakFinder</h4>
<p>The mountains are calling! Explore more mountains than any mountaineer! PeakFinder Earth makes it possible… and shows the names of all mountains and peaks with a 360° panorama display. This functions completely offline – and worldwide! PeakFinder knows more than 250’000 peaks - from Mount Everest to the little hill around the corner. Also mobile.</p>
<h3 id="2cmachinelearning">2c. Machine Learning</h3>
<p>This is the most ambitious approach, and it involves utilizing high-performance computing and deep-learning to match a corpus of photos against a training set which could be from user-contributed photos from Flickr and Instagram as well as from both appeals to general public and targeted expeditions that capture extensive imagery using a backpack-mounted camera rig. The basic idea is to match known locations photos with the photos that don’t have location. If a substantive match is found, then we know the location. If and exact match is not found then we continue matching, making the selection set smaller until we find a good enough match.</p>
<h2 id="step3displayanddisseminate">Step 3: Display and Disseminate</h2>
<h3 id="examplesforinspiration">Examples for Inspiration</h3>
<h4 id="mapwarper">Map Warper</h4>
<p>The NYPL Map Warper is a tool for digitally aligning ("rectifying") historical maps from the NYPL's collections to match today's precise maps. Visitors can browse already rectified maps or assist the NYPL by aligning a map. Play the video above to tour the site and learn how to rectify a map yourself. Everyone is welcome to participate!</p>
<h4 id="oldnyc">OLD NYC</h4>
<p>Mapping historical photos from the NYPL. This site provides an alternative way of browsing the NYPL's incredible Photographic Views of New York City, 1870s-1970s collection. Its goal is to help you discover the history behind the places you see every day.</p>
<h4 id="digitalcollections">Digital Collections</h4>
<p>Explore 695,287 items digitized from The New York Public Library's collections. This site is a living database with new materials added every day, featuring prints, photographs, maps, manuscripts, streaming video, and more.</p>
<h4 id="buildinginspector">Building Inspector</h4>
<p>For years The New York Public Library has collected maps documenting our ever-changing metropolis. Originally commissioned by insurance companies to assess property value and fire risk, these street atlases contain a wealth of detailed information about a city now largely lost to us: buildings long ago destroyed, streets renamed, whole neighborhoods redrawn or redefined. Making these lost places findable via contemporary digital maps allows us to drill down through the layers of urban change and study the city in profound new ways. But harvesting the data isn't easy.</p>
<p>That's where the Building Inspector (and you) come in. This app is the latest in a series of public-facing tools designed by The New York Public Library Labs to extract, correct and analyze data from historical maps. We're training computers to do the heavy lifting, and then distributing the remaining quality control tasks to smart, conscientious citizens like you. The goal? To produce a comprehensive directory of old New York (or, as we like to think of it, a time machine).</p>
<h4 id="spacetime">Space Time</h4>
<p>The New York Public Library is planning a major civic initiative aimed at turning historical maps and other geographic sources into a digital time-travel service for New York City.</p>
<h4 id="publicdomainvisualization">Public Domain Visualization</h4>
<p>On January 6th, 2016, The New York Public Library made over 187K digital items in the public domain available for high resolution download. This is one of many experiments by the NYPL Labs to help patrons understand and explore what was contained in that release.</p>
<h2 id="resources">Resources</h2>
<h3 id="coderepos">Code Repos</h3>
<h4 id="newyorkpubliclibrary">New York Public Library</h4>
<p>Based dually at the Library’s landmark central branch on 42nd Street and at its cutting-edge services center in Long Island City, <a href="https://github.com/NYPL-publicdomain">NYPL Labs</a> is an interdisciplinary team working to reformat and reposition the Library's knowledge for the Internet age. Labs combines core digital library operations (digitization, metadata, permissions/reproductions, etc.) with a publicly engaged tech, design, and outreach team focused on enabling new uses of collections and data, collaborating with users on the creation of digital resources, and applying new technologies to library problem-solving.</p>
<h3 id="cloudservices">Cloud Services</h3>
<h4 id="amazonearth">Amazon Earth</h4>
<p>Build planetary-scale applications in the cloud with open geospatial data on <a href="https://aws.amazon.com/earth/">Amazon Earth</a>. AWS Cloud Credits for Research are available for anyone to conduct research using Earth Observation data on AWS. Students, educators, and researchers are key drivers of technological innovation and we want to support new advances in the field.</p>
<h4 id="googleearthengine">Google Earth Engine</h4>
<p>A planetary-scale platform for earth science data and analysis, <a href="https://earthengine.google.com">Google Earth Engine</a> combines a multi-petabyte catalog of satellite imagery and geospatial datasets with planetary-scale analysis capabilities and makes it available for scientists, researchers, and developers to detect changes, map trends, and quantify differences on the Earth's surface.
Other Tools</p>
<h4 id="gpsprune">GpsPrune</h4>
<p><a href="http://activityworkshop.net/software/gpsprune/">GpsPrune</a> is an application for viewing, editing and converting coordinate data from GPS systems letting you play with your GPS data after you get home from your trip. It can load data from arbitrary text-based formats (for example, any tab-separated or comma-separated file) or Xml, or directly from a GPS receiver. It can display the data (as map view using openstreetmap images and as altitude profile), edit this data (for example delete points and ranges, sort waypoints, compress tracks), and save the data (in various text-based formats). It can also export data as a Gpx file, or as Kml/Kmz, or send it to a GPS receiver. Example uses of GpsPrune include cleaning up tracks by deleting wayward points - either recorded by error or by unintended detours. It can also be used to compare and combine tracks, convert to and from various formats, compress tracks, export data to Google Earth, or to analyse data to calculate distances, altitudes and so on.</p></div>

    <ul class="tags">
        <li><a href="/entries?q=tags:geotagging">geotagging</a></li>
        <li><a href="/entries?q=tags:photos">photos</a></li>
        <li><a href="/entries?q=tags:Göttingen">Göttingen</a></li>
    </ul>

    <ul class="bottomNav">
        <li class="prev"><a href="punkish/Potimarron">↜ Potimarron</a></li>
        <li class="next"><a href="punkish/Paris-Plage">Paris Plage ⇝</a></li>
    </ul></section></main>

    <footer><p>Dedicated to the public domain under the <a href="https://creativecommons.org/publicdomain/zero/1.0/legalcode" target="_blank">CC0 Public Domain Dedication</a></p></footer>

    <script src="punkish/_lib/JavaScript-autoComplete/auto-complete.js"></script>
    <script src="punkish/_lib/js/polyfill.js"></script>
    <script src="punkish/_lib/js/punkish.js"></script>
    
    
    
    
    
    
    <script>
        window.onload = function() {
            PK.autocomplete();
            PK.initializeDictionary();
    
            const searchInPage = document.getElementById('searchInPage')
            if (searchInPage) {
                const inp = document.getElementsByName('tag')
                inp[0].addEventListener('keyup', PK.searchInPage)
            }
        }
    </script>
    
</body>
</html>